{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Major_project_Model1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgRnexVnwOrw"
      },
      "source": [
        "# Loading Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZSJbOvarfJM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOFOsvZdi6Tf",
        "outputId": "ee0cb760-146a-48df-b3b7-c1a7d0488c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "raw_data = pd.read_csv('total_data.csv') # Change this later if needed\n",
        "#Dropping Multiple Indexes\n",
        "raw_data = raw_data.drop(raw_data.columns[0],axis= 1)\n",
        "raw_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>away_current_pos</th>\n",
              "      <th>away_last_yr_pos</th>\n",
              "      <th>away_prev_game_perf</th>\n",
              "      <th>away_team_av_points</th>\n",
              "      <th>away_team_av_points_conceded</th>\n",
              "      <th>away_team_away_form</th>\n",
              "      <th>away_team_form</th>\n",
              "      <th>away_team_rest_time</th>\n",
              "      <th>away_win_percentage</th>\n",
              "      <th>h2h_form</th>\n",
              "      <th>home_current_pos</th>\n",
              "      <th>home_last_yr_pos</th>\n",
              "      <th>home_prev_game_perf</th>\n",
              "      <th>home_team_av_points</th>\n",
              "      <th>home_team_av_points_conceded</th>\n",
              "      <th>home_team_form</th>\n",
              "      <th>home_team_home_form</th>\n",
              "      <th>home_team_rest_time</th>\n",
              "      <th>home_win_percentage</th>\n",
              "      <th>match_importance</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>20.4</td>\n",
              "      <td>20.64</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>20.85</td>\n",
              "      <td>20.55</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   away_current_pos  away_last_yr_pos  ...  match_importance  result\n",
              "0                12                12  ...                 0       1\n",
              "1                11                 6  ...                 0       1\n",
              "2                15                 3  ...                 0       1\n",
              "3                11                 8  ...                 0       1\n",
              "4                15                 3  ...                 0       0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WyoX3-8wD7z"
      },
      "source": [
        "# Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxcPtV1a4KTU",
        "outputId": "2ffb9ac3-c1e3-4943-9fb2-28f951465bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "X_raw = pd.DataFrame(data = raw_data)\n",
        "X_raw = X_raw.drop(columns='result',axis = 1)\n",
        "display.display(X_raw.head())\n",
        "Y_raw = raw_data['result']\n",
        "display.display(Y_raw.head())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>away_current_pos</th>\n",
              "      <th>away_last_yr_pos</th>\n",
              "      <th>away_prev_game_perf</th>\n",
              "      <th>away_team_av_points</th>\n",
              "      <th>away_team_av_points_conceded</th>\n",
              "      <th>away_team_away_form</th>\n",
              "      <th>away_team_form</th>\n",
              "      <th>away_team_rest_time</th>\n",
              "      <th>away_win_percentage</th>\n",
              "      <th>h2h_form</th>\n",
              "      <th>home_current_pos</th>\n",
              "      <th>home_last_yr_pos</th>\n",
              "      <th>home_prev_game_perf</th>\n",
              "      <th>home_team_av_points</th>\n",
              "      <th>home_team_av_points_conceded</th>\n",
              "      <th>home_team_form</th>\n",
              "      <th>home_team_home_form</th>\n",
              "      <th>home_team_rest_time</th>\n",
              "      <th>home_win_percentage</th>\n",
              "      <th>match_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>20.4</td>\n",
              "      <td>20.64</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>20.85</td>\n",
              "      <td>20.55</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   away_current_pos  away_last_yr_pos  ...  home_win_percentage  match_importance\n",
              "0                12                12  ...                 50.0                 0\n",
              "1                11                 6  ...                 50.0                 0\n",
              "2                15                 3  ...                 50.0                 0\n",
              "3                11                 8  ...                 50.0                 0\n",
              "4                15                 3  ...                100.0                 0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    0\n",
              "Name: result, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYvBkAvk7RNe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED = 2022\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_raw, Y_raw, test_size=0.2, random_state=RANDOM_SEED)\n",
        "x_train, x_val, y_train, y_val = train_test_split(X_raw, Y_raw, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7bixkk9x6-R",
        "outputId": "af02aa1d-9cd7-496f-a7e4-70961fda7788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "x_train.describe()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>away_current_pos</th>\n",
              "      <th>away_last_yr_pos</th>\n",
              "      <th>away_prev_game_perf</th>\n",
              "      <th>away_team_av_points</th>\n",
              "      <th>away_team_av_points_conceded</th>\n",
              "      <th>away_team_away_form</th>\n",
              "      <th>away_team_form</th>\n",
              "      <th>away_team_rest_time</th>\n",
              "      <th>away_win_percentage</th>\n",
              "      <th>h2h_form</th>\n",
              "      <th>home_current_pos</th>\n",
              "      <th>home_last_yr_pos</th>\n",
              "      <th>home_prev_game_perf</th>\n",
              "      <th>home_team_av_points</th>\n",
              "      <th>home_team_av_points_conceded</th>\n",
              "      <th>home_team_form</th>\n",
              "      <th>home_team_home_form</th>\n",
              "      <th>home_team_rest_time</th>\n",
              "      <th>home_win_percentage</th>\n",
              "      <th>match_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.666667</td>\n",
              "      <td>6.382752</td>\n",
              "      <td>0.525194</td>\n",
              "      <td>22.126070</td>\n",
              "      <td>22.038733</td>\n",
              "      <td>-0.161334</td>\n",
              "      <td>0.070521</td>\n",
              "      <td>3.913760</td>\n",
              "      <td>51.708333</td>\n",
              "      <td>0.005266</td>\n",
              "      <td>6.506783</td>\n",
              "      <td>6.258721</td>\n",
              "      <td>0.491279</td>\n",
              "      <td>22.133878</td>\n",
              "      <td>22.022503</td>\n",
              "      <td>0.067978</td>\n",
              "      <td>0.330916</td>\n",
              "      <td>3.893411</td>\n",
              "      <td>53.274208</td>\n",
              "      <td>0.313953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.635867</td>\n",
              "      <td>3.495572</td>\n",
              "      <td>0.499607</td>\n",
              "      <td>1.502859</td>\n",
              "      <td>1.402176</td>\n",
              "      <td>1.097777</td>\n",
              "      <td>1.202012</td>\n",
              "      <td>19.663792</td>\n",
              "      <td>28.842465</td>\n",
              "      <td>0.822970</td>\n",
              "      <td>3.650858</td>\n",
              "      <td>3.514405</td>\n",
              "      <td>0.500166</td>\n",
              "      <td>1.481427</td>\n",
              "      <td>1.435538</td>\n",
              "      <td>1.198980</td>\n",
              "      <td>1.158676</td>\n",
              "      <td>19.572846</td>\n",
              "      <td>28.424510</td>\n",
              "      <td>0.706269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.294816</td>\n",
              "      <td>16.565196</td>\n",
              "      <td>-2.701142</td>\n",
              "      <td>-2.584464</td>\n",
              "      <td>-362.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.513461</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.641108</td>\n",
              "      <td>16.585490</td>\n",
              "      <td>-2.667571</td>\n",
              "      <td>-2.471529</td>\n",
              "      <td>-362.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.074153</td>\n",
              "      <td>21.173538</td>\n",
              "      <td>-1.012919</td>\n",
              "      <td>-0.790927</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>-0.465117</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.080447</td>\n",
              "      <td>21.130296</td>\n",
              "      <td>-0.825200</td>\n",
              "      <td>-0.516720</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>22.256022</td>\n",
              "      <td>22.100876</td>\n",
              "      <td>-0.156998</td>\n",
              "      <td>0.026377</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.231275</td>\n",
              "      <td>22.056996</td>\n",
              "      <td>0.096348</td>\n",
              "      <td>0.331382</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>23.272775</td>\n",
              "      <td>23.038797</td>\n",
              "      <td>0.624679</td>\n",
              "      <td>1.018924</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.479971</td>\n",
              "      <td>9.250000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>23.300751</td>\n",
              "      <td>23.118568</td>\n",
              "      <td>0.935343</td>\n",
              "      <td>1.242873</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.387892</td>\n",
              "      <td>25.022770</td>\n",
              "      <td>2.705412</td>\n",
              "      <td>2.758960</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.449891</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.674567</td>\n",
              "      <td>24.984373</td>\n",
              "      <td>2.845735</td>\n",
              "      <td>2.763209</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       away_current_pos  ...  match_importance\n",
              "count       1032.000000  ...       1032.000000\n",
              "mean           6.666667  ...          0.313953\n",
              "std            3.635867  ...          0.706269\n",
              "min            1.000000  ...          0.000000\n",
              "25%            4.000000  ...          0.000000\n",
              "50%            6.000000  ...          0.000000\n",
              "75%           10.000000  ...          0.000000\n",
              "max           15.000000  ...          3.000000\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cMphVVYyE3a",
        "outputId": "10695025-3eb9-403e-88f1-eaaaa66bf6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.info(verbose=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1032 entries, 312 to 893\n",
            "Data columns (total 20 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   away_current_pos              1032 non-null   int64  \n",
            " 1   away_last_yr_pos              1032 non-null   int64  \n",
            " 2   away_prev_game_perf           1032 non-null   int64  \n",
            " 3   away_team_av_points           1032 non-null   float64\n",
            " 4   away_team_av_points_conceded  1032 non-null   float64\n",
            " 5   away_team_away_form           1032 non-null   float64\n",
            " 6   away_team_form                1032 non-null   float64\n",
            " 7   away_team_rest_time           1032 non-null   int64  \n",
            " 8   away_win_percentage           1032 non-null   float64\n",
            " 9   h2h_form                      1032 non-null   float64\n",
            " 10  home_current_pos              1032 non-null   int64  \n",
            " 11  home_last_yr_pos              1032 non-null   int64  \n",
            " 12  home_prev_game_perf           1032 non-null   int64  \n",
            " 13  home_team_av_points           1032 non-null   float64\n",
            " 14  home_team_av_points_conceded  1032 non-null   float64\n",
            " 15  home_team_form                1032 non-null   float64\n",
            " 16  home_team_home_form           1032 non-null   float64\n",
            " 17  home_team_rest_time           1032 non-null   int64  \n",
            " 18  home_win_percentage           1032 non-null   float64\n",
            " 19  match_importance              1032 non-null   int64  \n",
            "dtypes: float64(11), int64(9)\n",
            "memory usage: 169.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4npJS_iyMJ-",
        "outputId": "fcc41644-1ef8-404e-88a2-3f6b80e0d552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# # Checking Correlation between the columns\n",
        "# # Compute the correlation matrix\n",
        "# corr = x_train.corr()\n",
        "\n",
        "# # Set up the matplotlib figure\n",
        "# f, ax = plt.subplots(figsize=(20, 20))\n",
        "\n",
        "\n",
        "# # Generate a mask for the upper triangle\n",
        "# mask = np.zeros_like(corr, dtype=np.bool)\n",
        "# mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# # Draw the heatmap with the mask and correct aspect ratio\n",
        "\n",
        "# sns.heatmap(corr, mask = mask,linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d891cb7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQRYV5u3yQQ",
        "outputId": "6e1bd16d-1151-431a-b615-336fc0ac41eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print(corr.shape)\n",
        "# print(type(corr))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 20)\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf0-a4HCz0p0",
        "outputId": "2cdfba12-3153-4580-91c4-b62769d5643c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# corr"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>away_current_pos</th>\n",
              "      <th>away_last_yr_pos</th>\n",
              "      <th>away_prev_game_perf</th>\n",
              "      <th>away_team_av_points</th>\n",
              "      <th>away_team_av_points_conceded</th>\n",
              "      <th>away_team_away_form</th>\n",
              "      <th>away_team_form</th>\n",
              "      <th>away_team_rest_time</th>\n",
              "      <th>away_win_percentage</th>\n",
              "      <th>h2h_form</th>\n",
              "      <th>home_current_pos</th>\n",
              "      <th>home_last_yr_pos</th>\n",
              "      <th>home_prev_game_perf</th>\n",
              "      <th>home_team_av_points</th>\n",
              "      <th>home_team_av_points_conceded</th>\n",
              "      <th>home_team_form</th>\n",
              "      <th>home_team_home_form</th>\n",
              "      <th>home_team_rest_time</th>\n",
              "      <th>home_win_percentage</th>\n",
              "      <th>match_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>away_current_pos</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.683002</td>\n",
              "      <td>-0.504232</td>\n",
              "      <td>-0.654145</td>\n",
              "      <td>0.539973</td>\n",
              "      <td>-0.780486</td>\n",
              "      <td>-0.841734</td>\n",
              "      <td>0.071730</td>\n",
              "      <td>-0.890209</td>\n",
              "      <td>0.349193</td>\n",
              "      <td>0.105172</td>\n",
              "      <td>0.058372</td>\n",
              "      <td>0.022401</td>\n",
              "      <td>-0.055497</td>\n",
              "      <td>-0.003634</td>\n",
              "      <td>-0.045798</td>\n",
              "      <td>-0.100263</td>\n",
              "      <td>0.066366</td>\n",
              "      <td>-0.072491</td>\n",
              "      <td>-0.206987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_last_yr_pos</th>\n",
              "      <td>0.683002</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.357919</td>\n",
              "      <td>-0.533487</td>\n",
              "      <td>0.450489</td>\n",
              "      <td>-0.694080</td>\n",
              "      <td>-0.690632</td>\n",
              "      <td>0.054328</td>\n",
              "      <td>-0.668744</td>\n",
              "      <td>0.438494</td>\n",
              "      <td>0.014427</td>\n",
              "      <td>-0.028123</td>\n",
              "      <td>0.066541</td>\n",
              "      <td>-0.013316</td>\n",
              "      <td>-0.007860</td>\n",
              "      <td>-0.007388</td>\n",
              "      <td>-0.032820</td>\n",
              "      <td>0.050739</td>\n",
              "      <td>-0.006689</td>\n",
              "      <td>-0.106080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_prev_game_perf</th>\n",
              "      <td>-0.504232</td>\n",
              "      <td>-0.357919</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.442823</td>\n",
              "      <td>-0.416150</td>\n",
              "      <td>0.456881</td>\n",
              "      <td>0.631266</td>\n",
              "      <td>-0.020857</td>\n",
              "      <td>0.566024</td>\n",
              "      <td>-0.208783</td>\n",
              "      <td>-0.026948</td>\n",
              "      <td>0.006504</td>\n",
              "      <td>-0.063164</td>\n",
              "      <td>-0.002122</td>\n",
              "      <td>-0.002132</td>\n",
              "      <td>-0.011865</td>\n",
              "      <td>0.012723</td>\n",
              "      <td>-0.019067</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>0.073770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_team_av_points</th>\n",
              "      <td>-0.654145</td>\n",
              "      <td>-0.533487</td>\n",
              "      <td>0.442823</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.069811</td>\n",
              "      <td>0.634078</td>\n",
              "      <td>0.731130</td>\n",
              "      <td>-0.064836</td>\n",
              "      <td>0.654564</td>\n",
              "      <td>-0.289226</td>\n",
              "      <td>-0.075888</td>\n",
              "      <td>-0.049311</td>\n",
              "      <td>0.003950</td>\n",
              "      <td>0.370310</td>\n",
              "      <td>0.301062</td>\n",
              "      <td>0.054444</td>\n",
              "      <td>0.101651</td>\n",
              "      <td>-0.060292</td>\n",
              "      <td>0.060230</td>\n",
              "      <td>0.158282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_team_av_points_conceded</th>\n",
              "      <td>0.539973</td>\n",
              "      <td>0.450489</td>\n",
              "      <td>-0.416150</td>\n",
              "      <td>-0.069811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.628217</td>\n",
              "      <td>-0.681855</td>\n",
              "      <td>0.003380</td>\n",
              "      <td>-0.560865</td>\n",
              "      <td>0.295170</td>\n",
              "      <td>-0.011108</td>\n",
              "      <td>0.019416</td>\n",
              "      <td>0.094469</td>\n",
              "      <td>0.353516</td>\n",
              "      <td>0.332040</td>\n",
              "      <td>0.024294</td>\n",
              "      <td>-0.009473</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.001258</td>\n",
              "      <td>-0.039977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_team_away_form</th>\n",
              "      <td>-0.780486</td>\n",
              "      <td>-0.694080</td>\n",
              "      <td>0.456881</td>\n",
              "      <td>0.634078</td>\n",
              "      <td>-0.628217</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.878744</td>\n",
              "      <td>-0.072251</td>\n",
              "      <td>0.767733</td>\n",
              "      <td>-0.417678</td>\n",
              "      <td>-0.056510</td>\n",
              "      <td>-0.073107</td>\n",
              "      <td>-0.058500</td>\n",
              "      <td>0.030525</td>\n",
              "      <td>-0.011132</td>\n",
              "      <td>0.030447</td>\n",
              "      <td>0.096195</td>\n",
              "      <td>-0.066768</td>\n",
              "      <td>0.046408</td>\n",
              "      <td>0.161388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_team_form</th>\n",
              "      <td>-0.841734</td>\n",
              "      <td>-0.690632</td>\n",
              "      <td>0.631266</td>\n",
              "      <td>0.731130</td>\n",
              "      <td>-0.681855</td>\n",
              "      <td>0.878744</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.059129</td>\n",
              "      <td>0.860661</td>\n",
              "      <td>-0.390259</td>\n",
              "      <td>-0.048334</td>\n",
              "      <td>-0.054945</td>\n",
              "      <td>-0.062975</td>\n",
              "      <td>0.033319</td>\n",
              "      <td>-0.012962</td>\n",
              "      <td>0.025849</td>\n",
              "      <td>0.087722</td>\n",
              "      <td>-0.054110</td>\n",
              "      <td>0.042079</td>\n",
              "      <td>0.145651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_team_rest_time</th>\n",
              "      <td>0.071730</td>\n",
              "      <td>0.054328</td>\n",
              "      <td>-0.020857</td>\n",
              "      <td>-0.064836</td>\n",
              "      <td>0.003380</td>\n",
              "      <td>-0.072251</td>\n",
              "      <td>-0.059129</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.053186</td>\n",
              "      <td>-0.037981</td>\n",
              "      <td>0.073743</td>\n",
              "      <td>0.060717</td>\n",
              "      <td>-0.018074</td>\n",
              "      <td>-0.065719</td>\n",
              "      <td>0.026631</td>\n",
              "      <td>-0.067763</td>\n",
              "      <td>-0.085757</td>\n",
              "      <td>0.997606</td>\n",
              "      <td>-0.065501</td>\n",
              "      <td>0.025627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_win_percentage</th>\n",
              "      <td>-0.890209</td>\n",
              "      <td>-0.668744</td>\n",
              "      <td>0.566024</td>\n",
              "      <td>0.654564</td>\n",
              "      <td>-0.560865</td>\n",
              "      <td>0.767733</td>\n",
              "      <td>0.860661</td>\n",
              "      <td>-0.053186</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.353649</td>\n",
              "      <td>-0.049711</td>\n",
              "      <td>-0.038552</td>\n",
              "      <td>-0.037264</td>\n",
              "      <td>0.051593</td>\n",
              "      <td>0.016428</td>\n",
              "      <td>0.023585</td>\n",
              "      <td>0.080552</td>\n",
              "      <td>-0.049992</td>\n",
              "      <td>0.050683</td>\n",
              "      <td>0.126102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h2h_form</th>\n",
              "      <td>0.349193</td>\n",
              "      <td>0.438494</td>\n",
              "      <td>-0.208783</td>\n",
              "      <td>-0.289226</td>\n",
              "      <td>0.295170</td>\n",
              "      <td>-0.417678</td>\n",
              "      <td>-0.390259</td>\n",
              "      <td>-0.037981</td>\n",
              "      <td>-0.353649</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.391354</td>\n",
              "      <td>-0.447260</td>\n",
              "      <td>0.262751</td>\n",
              "      <td>0.314684</td>\n",
              "      <td>-0.309250</td>\n",
              "      <td>0.419788</td>\n",
              "      <td>0.400279</td>\n",
              "      <td>-0.044776</td>\n",
              "      <td>0.380595</td>\n",
              "      <td>0.046096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_current_pos</th>\n",
              "      <td>0.105172</td>\n",
              "      <td>0.014427</td>\n",
              "      <td>-0.026948</td>\n",
              "      <td>-0.075888</td>\n",
              "      <td>-0.011108</td>\n",
              "      <td>-0.056510</td>\n",
              "      <td>-0.048334</td>\n",
              "      <td>0.073743</td>\n",
              "      <td>-0.049711</td>\n",
              "      <td>-0.391354</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.703769</td>\n",
              "      <td>-0.484924</td>\n",
              "      <td>-0.647218</td>\n",
              "      <td>0.547784</td>\n",
              "      <td>-0.838077</td>\n",
              "      <td>-0.776587</td>\n",
              "      <td>0.078139</td>\n",
              "      <td>-0.894741</td>\n",
              "      <td>-0.232543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_last_yr_pos</th>\n",
              "      <td>0.058372</td>\n",
              "      <td>-0.028123</td>\n",
              "      <td>0.006504</td>\n",
              "      <td>-0.049311</td>\n",
              "      <td>0.019416</td>\n",
              "      <td>-0.073107</td>\n",
              "      <td>-0.054945</td>\n",
              "      <td>0.060717</td>\n",
              "      <td>-0.038552</td>\n",
              "      <td>-0.447260</td>\n",
              "      <td>0.703769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.320134</td>\n",
              "      <td>-0.531479</td>\n",
              "      <td>0.462922</td>\n",
              "      <td>-0.690514</td>\n",
              "      <td>-0.716906</td>\n",
              "      <td>0.064672</td>\n",
              "      <td>-0.664654</td>\n",
              "      <td>-0.150378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_prev_game_perf</th>\n",
              "      <td>0.022401</td>\n",
              "      <td>0.066541</td>\n",
              "      <td>-0.063164</td>\n",
              "      <td>0.003950</td>\n",
              "      <td>0.094469</td>\n",
              "      <td>-0.058500</td>\n",
              "      <td>-0.062975</td>\n",
              "      <td>-0.018074</td>\n",
              "      <td>-0.037264</td>\n",
              "      <td>0.262751</td>\n",
              "      <td>-0.484924</td>\n",
              "      <td>-0.320134</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.423166</td>\n",
              "      <td>-0.372391</td>\n",
              "      <td>0.598592</td>\n",
              "      <td>0.422064</td>\n",
              "      <td>-0.021000</td>\n",
              "      <td>0.530443</td>\n",
              "      <td>0.040707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_team_av_points</th>\n",
              "      <td>-0.055497</td>\n",
              "      <td>-0.013316</td>\n",
              "      <td>-0.002122</td>\n",
              "      <td>0.370310</td>\n",
              "      <td>0.353516</td>\n",
              "      <td>0.030525</td>\n",
              "      <td>0.033319</td>\n",
              "      <td>-0.065719</td>\n",
              "      <td>0.051593</td>\n",
              "      <td>0.314684</td>\n",
              "      <td>-0.647218</td>\n",
              "      <td>-0.531479</td>\n",
              "      <td>0.423166</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.075422</td>\n",
              "      <td>0.720459</td>\n",
              "      <td>0.677383</td>\n",
              "      <td>-0.068438</td>\n",
              "      <td>0.621513</td>\n",
              "      <td>0.183234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_team_av_points_conceded</th>\n",
              "      <td>-0.003634</td>\n",
              "      <td>-0.007860</td>\n",
              "      <td>-0.002132</td>\n",
              "      <td>0.301062</td>\n",
              "      <td>0.332040</td>\n",
              "      <td>-0.011132</td>\n",
              "      <td>-0.012962</td>\n",
              "      <td>0.026631</td>\n",
              "      <td>0.016428</td>\n",
              "      <td>-0.309250</td>\n",
              "      <td>0.547784</td>\n",
              "      <td>0.462922</td>\n",
              "      <td>-0.372391</td>\n",
              "      <td>-0.075422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.697823</td>\n",
              "      <td>-0.578721</td>\n",
              "      <td>0.027915</td>\n",
              "      <td>-0.590216</td>\n",
              "      <td>-0.055681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_team_form</th>\n",
              "      <td>-0.045798</td>\n",
              "      <td>-0.007388</td>\n",
              "      <td>-0.011865</td>\n",
              "      <td>0.054444</td>\n",
              "      <td>0.024294</td>\n",
              "      <td>0.030447</td>\n",
              "      <td>0.025849</td>\n",
              "      <td>-0.067763</td>\n",
              "      <td>0.023585</td>\n",
              "      <td>0.419788</td>\n",
              "      <td>-0.838077</td>\n",
              "      <td>-0.690514</td>\n",
              "      <td>0.598592</td>\n",
              "      <td>0.720459</td>\n",
              "      <td>-0.697823</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884079</td>\n",
              "      <td>-0.070548</td>\n",
              "      <td>0.855865</td>\n",
              "      <td>0.183973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_team_home_form</th>\n",
              "      <td>-0.100263</td>\n",
              "      <td>-0.032820</td>\n",
              "      <td>0.012723</td>\n",
              "      <td>0.101651</td>\n",
              "      <td>-0.009473</td>\n",
              "      <td>0.096195</td>\n",
              "      <td>0.087722</td>\n",
              "      <td>-0.085757</td>\n",
              "      <td>0.080552</td>\n",
              "      <td>0.400279</td>\n",
              "      <td>-0.776587</td>\n",
              "      <td>-0.716906</td>\n",
              "      <td>0.422064</td>\n",
              "      <td>0.677383</td>\n",
              "      <td>-0.578721</td>\n",
              "      <td>0.884079</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.088888</td>\n",
              "      <td>0.773564</td>\n",
              "      <td>0.201998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_team_rest_time</th>\n",
              "      <td>0.066366</td>\n",
              "      <td>0.050739</td>\n",
              "      <td>-0.019067</td>\n",
              "      <td>-0.060292</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>-0.066768</td>\n",
              "      <td>-0.054110</td>\n",
              "      <td>0.997606</td>\n",
              "      <td>-0.049992</td>\n",
              "      <td>-0.044776</td>\n",
              "      <td>0.078139</td>\n",
              "      <td>0.064672</td>\n",
              "      <td>-0.021000</td>\n",
              "      <td>-0.068438</td>\n",
              "      <td>0.027915</td>\n",
              "      <td>-0.070548</td>\n",
              "      <td>-0.088888</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.068628</td>\n",
              "      <td>0.026139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_win_percentage</th>\n",
              "      <td>-0.072491</td>\n",
              "      <td>-0.006689</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>0.060230</td>\n",
              "      <td>0.001258</td>\n",
              "      <td>0.046408</td>\n",
              "      <td>0.042079</td>\n",
              "      <td>-0.065501</td>\n",
              "      <td>0.050683</td>\n",
              "      <td>0.380595</td>\n",
              "      <td>-0.894741</td>\n",
              "      <td>-0.664654</td>\n",
              "      <td>0.530443</td>\n",
              "      <td>0.621513</td>\n",
              "      <td>-0.590216</td>\n",
              "      <td>0.855865</td>\n",
              "      <td>0.773564</td>\n",
              "      <td>-0.068628</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.176828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>match_importance</th>\n",
              "      <td>-0.206987</td>\n",
              "      <td>-0.106080</td>\n",
              "      <td>0.073770</td>\n",
              "      <td>0.158282</td>\n",
              "      <td>-0.039977</td>\n",
              "      <td>0.161388</td>\n",
              "      <td>0.145651</td>\n",
              "      <td>0.025627</td>\n",
              "      <td>0.126102</td>\n",
              "      <td>0.046096</td>\n",
              "      <td>-0.232543</td>\n",
              "      <td>-0.150378</td>\n",
              "      <td>0.040707</td>\n",
              "      <td>0.183234</td>\n",
              "      <td>-0.055681</td>\n",
              "      <td>0.183973</td>\n",
              "      <td>0.201998</td>\n",
              "      <td>0.026139</td>\n",
              "      <td>0.176828</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              away_current_pos  ...  match_importance\n",
              "away_current_pos                      1.000000  ...         -0.206987\n",
              "away_last_yr_pos                      0.683002  ...         -0.106080\n",
              "away_prev_game_perf                  -0.504232  ...          0.073770\n",
              "away_team_av_points                  -0.654145  ...          0.158282\n",
              "away_team_av_points_conceded          0.539973  ...         -0.039977\n",
              "away_team_away_form                  -0.780486  ...          0.161388\n",
              "away_team_form                       -0.841734  ...          0.145651\n",
              "away_team_rest_time                   0.071730  ...          0.025627\n",
              "away_win_percentage                  -0.890209  ...          0.126102\n",
              "h2h_form                              0.349193  ...          0.046096\n",
              "home_current_pos                      0.105172  ...         -0.232543\n",
              "home_last_yr_pos                      0.058372  ...         -0.150378\n",
              "home_prev_game_perf                   0.022401  ...          0.040707\n",
              "home_team_av_points                  -0.055497  ...          0.183234\n",
              "home_team_av_points_conceded         -0.003634  ...         -0.055681\n",
              "home_team_form                       -0.045798  ...          0.183973\n",
              "home_team_home_form                  -0.100263  ...          0.201998\n",
              "home_team_rest_time                   0.066366  ...          0.026139\n",
              "home_win_percentage                  -0.072491  ...          0.176828\n",
              "match_importance                     -0.206987  ...          1.000000\n",
              "\n",
              "[20 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYtcWu7c2PAT",
        "outputId": "d609812c-dcc2-4e2a-a34c-fb48a19c6a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# column_name = corr.columns\n",
        "# print(column_name)\n",
        "# print(len(column_name))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['away_current_pos', 'away_last_yr_pos', 'away_prev_game_perf',\n",
            "       'away_team_av_points', 'away_team_av_points_conceded',\n",
            "       'away_team_away_form', 'away_team_form', 'away_team_rest_time',\n",
            "       'away_win_percentage', 'h2h_form', 'home_current_pos',\n",
            "       'home_last_yr_pos', 'home_prev_game_perf', 'home_team_av_points',\n",
            "       'home_team_av_points_conceded', 'home_team_form', 'home_team_home_form',\n",
            "       'home_team_rest_time', 'home_win_percentage', 'match_importance'],\n",
            "      dtype='object')\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnbjoWujDjae",
        "outputId": "e17706b8-4cb7-43ad-ea22-0a93c1cc3ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "# from IPython import display\n",
        "# feature1 = []\n",
        "# feature2 = []\n",
        "# corr_f1f2 = []\n",
        "# for i in range(1,len(column_name)):\n",
        "#   for j in range(0,i):\n",
        "#     feature1.append(column_name[i])\n",
        "#     feature2.append(column_name[j])\n",
        "#     corr_f1f2.append(abs(corr.iloc[i,j]))\n",
        "#     j = 0;\n",
        "# corr_pairs = pd.DataFrame(data = feature1, columns = ['feature1'])\n",
        "# corr_pairs['feature2'] = feature2\n",
        "# corr_pairs['corr_f1f2'] = corr_f1f2\n",
        "# corr_pairs = corr_pairs.sort_values(by= ['corr_f1f2'],ascending = False, ignore_index = True)\n",
        "# display.display(corr_pairs)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>corr_f1f2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>home_team_rest_time</td>\n",
              "      <td>away_team_rest_time</td>\n",
              "      <td>0.997606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>home_win_percentage</td>\n",
              "      <td>home_current_pos</td>\n",
              "      <td>0.894741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>away_win_percentage</td>\n",
              "      <td>away_current_pos</td>\n",
              "      <td>0.890209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>home_team_home_form</td>\n",
              "      <td>home_team_form</td>\n",
              "      <td>0.884079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>away_team_form</td>\n",
              "      <td>away_team_away_form</td>\n",
              "      <td>0.878744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>away_team_rest_time</td>\n",
              "      <td>away_team_av_points_conceded</td>\n",
              "      <td>0.003380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>home_team_av_points_conceded</td>\n",
              "      <td>away_prev_game_perf</td>\n",
              "      <td>0.002132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>home_team_av_points</td>\n",
              "      <td>away_prev_game_perf</td>\n",
              "      <td>0.002122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>home_win_percentage</td>\n",
              "      <td>away_team_av_points_conceded</td>\n",
              "      <td>0.001258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>home_team_rest_time</td>\n",
              "      <td>away_team_av_points_conceded</td>\n",
              "      <td>0.001089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>190 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         feature1                      feature2  corr_f1f2\n",
              "0             home_team_rest_time           away_team_rest_time   0.997606\n",
              "1             home_win_percentage              home_current_pos   0.894741\n",
              "2             away_win_percentage              away_current_pos   0.890209\n",
              "3             home_team_home_form                home_team_form   0.884079\n",
              "4                  away_team_form           away_team_away_form   0.878744\n",
              "..                            ...                           ...        ...\n",
              "185           away_team_rest_time  away_team_av_points_conceded   0.003380\n",
              "186  home_team_av_points_conceded           away_prev_game_perf   0.002132\n",
              "187           home_team_av_points           away_prev_game_perf   0.002122\n",
              "188           home_win_percentage  away_team_av_points_conceded   0.001258\n",
              "189           home_team_rest_time  away_team_av_points_conceded   0.001089\n",
              "\n",
              "[190 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou3COGhOGEHx"
      },
      "source": [
        "# Standardizing the features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()# Fit on training set only.\n",
        "scaler.fit(x_train)\n",
        "# Apply transform to all the training set,the validation set,the test set.\n",
        "x_train = scaler.transform(x_train)\n",
        "X_val = scaler.transform(x_val)\n",
        "X_test = scaler.transform(x_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlV5i60B2gc7"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA(.95)\n",
        "#Fitting the model on the training set\n",
        "pca.fit(x_train)\n",
        "# Apply transform to all the training set,the validation set,the test set.\n",
        "x_train = pca.transform(x_train)\n",
        "x_val= pca.transform(x_val)\n",
        "x_test = pca.transform(x_test)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymn7mrZjIHMg",
        "outputId": "1e23b7ef-bb06-43c0-a5ef-2c046ead639f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Number of features after applying PCA transformation\n",
        "pca.n_components_"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_WCnh9BJQkY"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnStMS0jOh3g",
        "outputId": "e56e5bcb-3e47-4e9a-931f-2efb83773d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('x_train shape',x_train.shape)\n",
        "print('x_val shape',x_val.shape)\n",
        "print('x_test shape',x_test.shape)\n",
        "print('y_train shape',x_train.shape)\n",
        "print('y_val shape',x_val.shape)\n",
        "print('y_test shape',x_test.shape)\n",
        "print('type of x',type(x_train),'type of y',type(y_train))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape (1032, 12)\n",
            "x_val shape (258, 12)\n",
            "x_test shape (258, 12)\n",
            "y_train shape (1032, 12)\n",
            "y_val shape (258, 12)\n",
            "y_test shape (258, 12)\n",
            "type of x <class 'numpy.ndarray'> type of y <class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P34zPUI3Jgkt"
      },
      "source": [
        "# Model Building\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
        "model = keras.Sequential()\n",
        "model.add(Dense(12, input_shape = (12,)))\n",
        "model.add(Dense(20, activation = 'relu'))\n",
        "model.add(Dense(20, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozy0_Rj3YpD4",
        "outputId": "a7005edc-4f2e-4a3e-80d0-776541d161f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 20)                260       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 857\n",
            "Trainable params: 857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz4ZVlPPaNSH"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gaCEzEcaP0k"
      },
      "source": [
        "model.compile( optimizer = 'adam',loss ='binary_crossentropy',metrics=['accuracy', tf.keras.metrics.AUC()] )"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7G5bI0d1qB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTyav92mbZ8o",
        "outputId": "c095e701-b3b0-4b1b-8362-166d1efdceca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# saved model checkpoint file\n",
        "best_model_file=\"./model1.hdf5\"\n",
        "MAX_PATIENT=12\n",
        "MAX_EPOCHS= 500\n",
        "BATCH_SIZE=20\n",
        "\n",
        "callback=[ReduceLROnPlateau(patience=MAX_PATIENT, verbose=1),\n",
        "          ModelCheckpoint(filepath=best_model_file, monitor='val_loss', verbose=1, save_best_only=True)]\n",
        "# training\n",
        "history=model.fit(tf.convert_to_tensor(x_train), tf.convert_to_tensor(y_train), \n",
        "                  batch_size=BATCH_SIZE, \n",
        "                  epochs=MAX_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(tf.convert_to_tensor(x_val), tf.convert_to_tensor(y_val)),\n",
        "                  callbacks=callback) "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.6017 - accuracy: 0.6757 - auc_2: 0.7473\n",
            "Epoch 00001: val_loss improved from inf to 4.34859, saving model to ./model1.hdf5\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5937 - accuracy: 0.6880 - auc_2: 0.7508 - val_loss: 4.3486 - val_accuracy: 0.5930 - val_auc_2: 0.7088\n",
            "Epoch 2/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.5446 - accuracy: 0.7357 - auc_2: 0.7918\n",
            "Epoch 00002: val_loss improved from 4.34859 to 3.43389, saving model to ./model1.hdf5\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7345 - auc_2: 0.7959 - val_loss: 3.4339 - val_accuracy: 0.6860 - val_auc_2: 0.7523\n",
            "Epoch 3/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.5284 - accuracy: 0.7395 - auc_2: 0.8076\n",
            "Epoch 00003: val_loss improved from 3.43389 to 3.27893, saving model to ./model1.hdf5\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7393 - auc_2: 0.8102 - val_loss: 3.2789 - val_accuracy: 0.7016 - val_auc_2: 0.7531\n",
            "Epoch 4/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.5057 - accuracy: 0.7500 - auc_2: 0.8240\n",
            "Epoch 00004: val_loss improved from 3.27893 to 2.95426, saving model to ./model1.hdf5\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7393 - auc_2: 0.8167 - val_loss: 2.9543 - val_accuracy: 0.7248 - val_auc_2: 0.7548\n",
            "Epoch 5/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.5173 - accuracy: 0.7378 - auc_2: 0.8154\n",
            "Epoch 00005: val_loss did not improve from 2.95426\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7403 - auc_2: 0.8220 - val_loss: 2.9673 - val_accuracy: 0.7132 - val_auc_2: 0.7597\n",
            "Epoch 6/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.5156 - accuracy: 0.7348 - auc_2: 0.8183\n",
            "Epoch 00006: val_loss improved from 2.95426 to 2.92465, saving model to ./model1.hdf5\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7393 - auc_2: 0.8252 - val_loss: 2.9246 - val_accuracy: 0.7248 - val_auc_2: 0.7690\n",
            "Epoch 7/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.5040 - accuracy: 0.7411 - auc_2: 0.8286\n",
            "Epoch 00007: val_loss improved from 2.92465 to 2.81551, saving model to ./model1.hdf5\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7413 - auc_2: 0.8284 - val_loss: 2.8155 - val_accuracy: 0.7248 - val_auc_2: 0.7706\n",
            "Epoch 8/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4998 - accuracy: 0.7361 - auc_2: 0.8295\n",
            "Epoch 00008: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7413 - auc_2: 0.8301 - val_loss: 3.0564 - val_accuracy: 0.7132 - val_auc_2: 0.7601\n",
            "Epoch 9/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4995 - accuracy: 0.7402 - auc_2: 0.8315\n",
            "Epoch 00009: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7471 - auc_2: 0.8321 - val_loss: 2.9722 - val_accuracy: 0.7248 - val_auc_2: 0.7637\n",
            "Epoch 10/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4861 - accuracy: 0.7581 - auc_2: 0.8417\n",
            "Epoch 00010: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7471 - auc_2: 0.8337 - val_loss: 2.9942 - val_accuracy: 0.7171 - val_auc_2: 0.7607\n",
            "Epoch 11/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.4962 - accuracy: 0.7500 - auc_2: 0.8342\n",
            "Epoch 00011: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7558 - auc_2: 0.8364 - val_loss: 2.9011 - val_accuracy: 0.7132 - val_auc_2: 0.7577\n",
            "Epoch 12/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4884 - accuracy: 0.7512 - auc_2: 0.8411\n",
            "Epoch 00012: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7510 - auc_2: 0.8373 - val_loss: 3.0129 - val_accuracy: 0.7054 - val_auc_2: 0.7560\n",
            "Epoch 13/500\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.4859 - accuracy: 0.7543 - auc_2: 0.8411\n",
            "Epoch 00013: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7519 - auc_2: 0.8395 - val_loss: 3.1461 - val_accuracy: 0.7093 - val_auc_2: 0.7523\n",
            "Epoch 14/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4828 - accuracy: 0.7571 - auc_2: 0.8442\n",
            "Epoch 00014: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7578 - auc_2: 0.8406 - val_loss: 3.1661 - val_accuracy: 0.7093 - val_auc_2: 0.7521\n",
            "Epoch 15/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4892 - accuracy: 0.7632 - auc_2: 0.8363\n",
            "Epoch 00015: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7665 - auc_2: 0.8435 - val_loss: 3.2912 - val_accuracy: 0.7093 - val_auc_2: 0.7457\n",
            "Epoch 16/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4667 - accuracy: 0.7705 - auc_2: 0.8573\n",
            "Epoch 00016: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7587 - auc_2: 0.8439 - val_loss: 3.3307 - val_accuracy: 0.7093 - val_auc_2: 0.7451\n",
            "Epoch 17/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4781 - accuracy: 0.7695 - auc_2: 0.8502\n",
            "Epoch 00017: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7645 - auc_2: 0.8478 - val_loss: 3.4155 - val_accuracy: 0.7132 - val_auc_2: 0.7469\n",
            "Epoch 18/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4805 - accuracy: 0.7567 - auc_2: 0.8469\n",
            "Epoch 00018: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7597 - auc_2: 0.8492 - val_loss: 3.2778 - val_accuracy: 0.7054 - val_auc_2: 0.7484\n",
            "Epoch 19/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4578 - accuracy: 0.7732 - auc_2: 0.8640\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7626 - auc_2: 0.8491 - val_loss: 3.2193 - val_accuracy: 0.7054 - val_auc_2: 0.7491\n",
            "Epoch 20/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4779 - accuracy: 0.7645 - auc_2: 0.8483\n",
            "Epoch 00020: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7694 - auc_2: 0.8550 - val_loss: 3.1977 - val_accuracy: 0.7054 - val_auc_2: 0.7491\n",
            "Epoch 21/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4668 - accuracy: 0.7697 - auc_2: 0.8549\n",
            "Epoch 00021: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7723 - auc_2: 0.8554 - val_loss: 3.2109 - val_accuracy: 0.7054 - val_auc_2: 0.7466\n",
            "Epoch 22/500\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.4686 - accuracy: 0.7696 - auc_2: 0.8546\n",
            "Epoch 00022: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7723 - auc_2: 0.8558 - val_loss: 3.2229 - val_accuracy: 0.7054 - val_auc_2: 0.7495\n",
            "Epoch 23/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4628 - accuracy: 0.7744 - auc_2: 0.8611\n",
            "Epoch 00023: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7713 - auc_2: 0.8559 - val_loss: 3.2493 - val_accuracy: 0.7054 - val_auc_2: 0.7496\n",
            "Epoch 24/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4720 - accuracy: 0.7726 - auc_2: 0.8536\n",
            "Epoch 00024: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7703 - auc_2: 0.8559 - val_loss: 3.2311 - val_accuracy: 0.7093 - val_auc_2: 0.7500\n",
            "Epoch 25/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.4627 - accuracy: 0.7778 - auc_2: 0.8598\n",
            "Epoch 00025: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7723 - auc_2: 0.8558 - val_loss: 3.2300 - val_accuracy: 0.7093 - val_auc_2: 0.7528\n",
            "Epoch 26/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4603 - accuracy: 0.7756 - auc_2: 0.8612\n",
            "Epoch 00026: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7713 - auc_2: 0.8561 - val_loss: 3.2604 - val_accuracy: 0.7093 - val_auc_2: 0.7501\n",
            "Epoch 27/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.4721 - accuracy: 0.7667 - auc_2: 0.8522\n",
            "Epoch 00027: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7723 - auc_2: 0.8563 - val_loss: 3.2562 - val_accuracy: 0.7093 - val_auc_2: 0.7496\n",
            "Epoch 28/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4670 - accuracy: 0.7757 - auc_2: 0.8553\n",
            "Epoch 00028: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7742 - auc_2: 0.8566 - val_loss: 3.2329 - val_accuracy: 0.7093 - val_auc_2: 0.7556\n",
            "Epoch 29/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4554 - accuracy: 0.7830 - auc_2: 0.8629\n",
            "Epoch 00029: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7733 - auc_2: 0.8567 - val_loss: 3.2347 - val_accuracy: 0.7093 - val_auc_2: 0.7560\n",
            "Epoch 30/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4581 - accuracy: 0.7826 - auc_2: 0.8611\n",
            "Epoch 00030: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7742 - auc_2: 0.8566 - val_loss: 3.2487 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 31/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4654 - accuracy: 0.7698 - auc_2: 0.8551\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7713 - auc_2: 0.8570 - val_loss: 3.2555 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 32/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4709 - accuracy: 0.7611 - auc_2: 0.8531\n",
            "Epoch 00032: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7713 - auc_2: 0.8575 - val_loss: 3.2581 - val_accuracy: 0.7093 - val_auc_2: 0.7539\n",
            "Epoch 33/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4774 - accuracy: 0.7571 - auc_2: 0.8468\n",
            "Epoch 00033: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7733 - auc_2: 0.8575 - val_loss: 3.2566 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 34/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4538 - accuracy: 0.7853 - auc_2: 0.8671\n",
            "Epoch 00034: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7713 - auc_2: 0.8576 - val_loss: 3.2567 - val_accuracy: 0.7093 - val_auc_2: 0.7526\n",
            "Epoch 35/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4567 - accuracy: 0.7767 - auc_2: 0.8630\n",
            "Epoch 00035: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7723 - auc_2: 0.8575 - val_loss: 3.2607 - val_accuracy: 0.7093 - val_auc_2: 0.7540\n",
            "Epoch 36/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4738 - accuracy: 0.7581 - auc_2: 0.8513\n",
            "Epoch 00036: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7733 - auc_2: 0.8575 - val_loss: 3.2565 - val_accuracy: 0.7093 - val_auc_2: 0.7526\n",
            "Epoch 37/500\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.4616 - accuracy: 0.7766 - auc_2: 0.8614\n",
            "Epoch 00037: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7733 - auc_2: 0.8575 - val_loss: 3.2607 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 38/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4620 - accuracy: 0.7739 - auc_2: 0.8583\n",
            "Epoch 00038: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7733 - auc_2: 0.8576 - val_loss: 3.2598 - val_accuracy: 0.7093 - val_auc_2: 0.7526\n",
            "Epoch 39/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4545 - accuracy: 0.7837 - auc_2: 0.8659\n",
            "Epoch 00039: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7733 - auc_2: 0.8575 - val_loss: 3.2587 - val_accuracy: 0.7093 - val_auc_2: 0.7529\n",
            "Epoch 40/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4825 - accuracy: 0.7566 - auc_2: 0.8447\n",
            "Epoch 00040: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7733 - auc_2: 0.8576 - val_loss: 3.2608 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 41/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.4684 - accuracy: 0.7733 - auc_2: 0.8552\n",
            "Epoch 00041: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2612 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 42/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4617 - accuracy: 0.7756 - auc_2: 0.8585\n",
            "Epoch 00042: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2619 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 43/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4667 - accuracy: 0.7773 - auc_2: 0.8565\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7742 - auc_2: 0.8575 - val_loss: 3.2633 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 44/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4569 - accuracy: 0.7805 - auc_2: 0.8625\n",
            "Epoch 00044: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2632 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 45/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4479 - accuracy: 0.7819 - auc_2: 0.8707\n",
            "Epoch 00045: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2631 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 46/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4711 - accuracy: 0.7797 - auc_2: 0.8552\n",
            "Epoch 00046: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7733 - auc_2: 0.8576 - val_loss: 3.2633 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 47/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4732 - accuracy: 0.7684 - auc_2: 0.8517\n",
            "Epoch 00047: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2634 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 48/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4653 - accuracy: 0.7756 - auc_2: 0.8565\n",
            "Epoch 00048: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2632 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 49/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.4713 - accuracy: 0.7700 - auc_2: 0.8509\n",
            "Epoch 00049: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2632 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 50/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4681 - accuracy: 0.7725 - auc_2: 0.8566\n",
            "Epoch 00050: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 51/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4695 - accuracy: 0.7667 - auc_2: 0.8559\n",
            "Epoch 00051: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2637 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 52/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4687 - accuracy: 0.7674 - auc_2: 0.8550\n",
            "Epoch 00052: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 53/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4620 - accuracy: 0.7716 - auc_2: 0.8583\n",
            "Epoch 00053: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2636 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 54/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4599 - accuracy: 0.7784 - auc_2: 0.8609\n",
            "Epoch 00054: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 55/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4561 - accuracy: 0.7837 - auc_2: 0.8641\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8576 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 56/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4639 - accuracy: 0.7797 - auc_2: 0.8535\n",
            "Epoch 00056: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 57/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4745 - accuracy: 0.7578 - auc_2: 0.8477\n",
            "Epoch 00057: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 58/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4670 - accuracy: 0.7695 - auc_2: 0.8548\n",
            "Epoch 00058: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 59/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4600 - accuracy: 0.7750 - auc_2: 0.8609\n",
            "Epoch 00059: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 60/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4755 - accuracy: 0.7634 - auc_2: 0.8488\n",
            "Epoch 00060: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 61/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4698 - accuracy: 0.7744 - auc_2: 0.8538\n",
            "Epoch 00061: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 62/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4689 - accuracy: 0.7707 - auc_2: 0.8529\n",
            "Epoch 00062: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 63/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4640 - accuracy: 0.7686 - auc_2: 0.8583\n",
            "Epoch 00063: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 64/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4713 - accuracy: 0.7679 - auc_2: 0.8524\n",
            "Epoch 00064: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 65/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4662 - accuracy: 0.7716 - auc_2: 0.8550\n",
            "Epoch 00065: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2636 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 66/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4779 - accuracy: 0.7592 - auc_2: 0.8462\n",
            "Epoch 00066: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 67/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4723 - accuracy: 0.7726 - auc_2: 0.8527\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 68/500\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.4661 - accuracy: 0.7750 - auc_2: 0.8567\n",
            "Epoch 00068: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 69/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4649 - accuracy: 0.7711 - auc_2: 0.8575\n",
            "Epoch 00069: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 70/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4616 - accuracy: 0.7779 - auc_2: 0.8606\n",
            "Epoch 00070: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 71/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4637 - accuracy: 0.7761 - auc_2: 0.8579\n",
            "Epoch 00071: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 72/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4730 - accuracy: 0.7726 - auc_2: 0.8513\n",
            "Epoch 00072: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 73/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4784 - accuracy: 0.7638 - auc_2: 0.8450\n",
            "Epoch 00073: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 74/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4633 - accuracy: 0.7721 - auc_2: 0.8593\n",
            "Epoch 00074: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 75/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4607 - accuracy: 0.7763 - auc_2: 0.8604\n",
            "Epoch 00075: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 76/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4762 - accuracy: 0.7674 - auc_2: 0.8494\n",
            "Epoch 00076: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 77/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4632 - accuracy: 0.7837 - auc_2: 0.8593\n",
            "Epoch 00077: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 78/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4626 - accuracy: 0.7786 - auc_2: 0.8593\n",
            "Epoch 00078: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 79/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4741 - accuracy: 0.7743 - auc_2: 0.8512\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 80/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4563 - accuracy: 0.7868 - auc_2: 0.8645\n",
            "Epoch 00080: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 81/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4697 - accuracy: 0.7636 - auc_2: 0.8530\n",
            "Epoch 00081: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 82/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4690 - accuracy: 0.7636 - auc_2: 0.8547\n",
            "Epoch 00082: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 83/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4683 - accuracy: 0.7732 - auc_2: 0.8556\n",
            "Epoch 00083: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 84/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4630 - accuracy: 0.7843 - auc_2: 0.8586\n",
            "Epoch 00084: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 85/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4554 - accuracy: 0.7806 - auc_2: 0.8655\n",
            "Epoch 00085: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 86/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4651 - accuracy: 0.7784 - auc_2: 0.8572\n",
            "Epoch 00086: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 87/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4654 - accuracy: 0.7683 - auc_2: 0.8567\n",
            "Epoch 00087: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 88/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4676 - accuracy: 0.7784 - auc_2: 0.8544\n",
            "Epoch 00088: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 89/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4572 - accuracy: 0.7786 - auc_2: 0.8629\n",
            "Epoch 00089: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 90/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4614 - accuracy: 0.7714 - auc_2: 0.8587\n",
            "Epoch 00090: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 91/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4606 - accuracy: 0.7756 - auc_2: 0.8606\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 92/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4761 - accuracy: 0.7689 - auc_2: 0.8492\n",
            "Epoch 00092: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 93/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4550 - accuracy: 0.7786 - auc_2: 0.8646\n",
            "Epoch 00093: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 94/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4800 - accuracy: 0.7619 - auc_2: 0.8463\n",
            "Epoch 00094: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 95/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4504 - accuracy: 0.7806 - auc_2: 0.8668\n",
            "Epoch 00095: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 96/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4759 - accuracy: 0.7679 - auc_2: 0.8481\n",
            "Epoch 00096: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 97/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4593 - accuracy: 0.7761 - auc_2: 0.8617\n",
            "Epoch 00097: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 98/500\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.4649 - accuracy: 0.7728 - auc_2: 0.8572\n",
            "Epoch 00098: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 99/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4722 - accuracy: 0.7774 - auc_2: 0.8533\n",
            "Epoch 00099: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 100/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4573 - accuracy: 0.7635 - auc_2: 0.8642\n",
            "Epoch 00100: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 101/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4802 - accuracy: 0.7667 - auc_2: 0.8459\n",
            "Epoch 00101: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 102/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4966 - accuracy: 0.7530 - auc_2: 0.8318\n",
            "Epoch 00102: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 103/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4719 - accuracy: 0.7726 - auc_2: 0.8519\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 104/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4606 - accuracy: 0.7759 - auc_2: 0.8599\n",
            "Epoch 00104: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 105/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4685 - accuracy: 0.7733 - auc_2: 0.8547\n",
            "Epoch 00105: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 106/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4600 - accuracy: 0.7800 - auc_2: 0.8615\n",
            "Epoch 00106: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 107/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4732 - accuracy: 0.7640 - auc_2: 0.8517\n",
            "Epoch 00107: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 108/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4525 - accuracy: 0.7800 - auc_2: 0.8693\n",
            "Epoch 00108: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 109/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4598 - accuracy: 0.7756 - auc_2: 0.8610\n",
            "Epoch 00109: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 110/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4589 - accuracy: 0.7757 - auc_2: 0.8611\n",
            "Epoch 00110: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 111/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4648 - accuracy: 0.7744 - auc_2: 0.8578\n",
            "Epoch 00111: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 112/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4461 - accuracy: 0.7838 - auc_2: 0.8706\n",
            "Epoch 00112: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 113/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4666 - accuracy: 0.7692 - auc_2: 0.8564\n",
            "Epoch 00113: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 114/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4573 - accuracy: 0.7808 - auc_2: 0.8638\n",
            "Epoch 00114: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 115/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4675 - accuracy: 0.7713 - auc_2: 0.8560\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 116/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4649 - accuracy: 0.7697 - auc_2: 0.8572\n",
            "Epoch 00116: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 117/500\n",
            "44/52 [========================>.....] - ETA: 0s - loss: 0.4605 - accuracy: 0.7784 - auc_2: 0.8610\n",
            "Epoch 00117: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 118/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4621 - accuracy: 0.7727 - auc_2: 0.8601\n",
            "Epoch 00118: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 119/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4645 - accuracy: 0.7708 - auc_2: 0.8562\n",
            "Epoch 00119: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 120/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4602 - accuracy: 0.7744 - auc_2: 0.8589\n",
            "Epoch 00120: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 121/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4951 - accuracy: 0.7517 - auc_2: 0.8334\n",
            "Epoch 00121: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 122/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4706 - accuracy: 0.7816 - auc_2: 0.8535\n",
            "Epoch 00122: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 123/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4707 - accuracy: 0.7656 - auc_2: 0.8509\n",
            "Epoch 00123: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 124/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4489 - accuracy: 0.7731 - auc_2: 0.8683\n",
            "Epoch 00124: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 125/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4570 - accuracy: 0.7750 - auc_2: 0.8653\n",
            "Epoch 00125: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 126/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4875 - accuracy: 0.7591 - auc_2: 0.8364\n",
            "Epoch 00126: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 127/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4712 - accuracy: 0.7702 - auc_2: 0.8530\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 128/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4614 - accuracy: 0.7734 - auc_2: 0.8607\n",
            "Epoch 00128: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 129/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4817 - accuracy: 0.7632 - auc_2: 0.8462\n",
            "Epoch 00129: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 130/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4513 - accuracy: 0.7846 - auc_2: 0.8670\n",
            "Epoch 00130: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 131/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4644 - accuracy: 0.7775 - auc_2: 0.8574\n",
            "Epoch 00131: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 132/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4726 - accuracy: 0.7707 - auc_2: 0.8526\n",
            "Epoch 00132: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 133/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4688 - accuracy: 0.7702 - auc_2: 0.8539\n",
            "Epoch 00133: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 134/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4638 - accuracy: 0.7705 - auc_2: 0.8578\n",
            "Epoch 00134: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 135/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4810 - accuracy: 0.7568 - auc_2: 0.8429\n",
            "Epoch 00135: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 136/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4660 - accuracy: 0.7718 - auc_2: 0.8566\n",
            "Epoch 00136: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 137/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4691 - accuracy: 0.7692 - auc_2: 0.8547\n",
            "Epoch 00137: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 138/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4477 - accuracy: 0.7765 - auc_2: 0.8708\n",
            "Epoch 00138: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 139/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4703 - accuracy: 0.7763 - auc_2: 0.8545\n",
            "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 140/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4623 - accuracy: 0.7718 - auc_2: 0.8586\n",
            "Epoch 00140: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 141/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4715 - accuracy: 0.7689 - auc_2: 0.8515\n",
            "Epoch 00141: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 142/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4561 - accuracy: 0.7825 - auc_2: 0.8632\n",
            "Epoch 00142: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 143/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4742 - accuracy: 0.7671 - auc_2: 0.8502\n",
            "Epoch 00143: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 144/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4611 - accuracy: 0.7738 - auc_2: 0.8604\n",
            "Epoch 00144: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 145/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4736 - accuracy: 0.7567 - auc_2: 0.8529\n",
            "Epoch 00145: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 146/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4663 - accuracy: 0.7786 - auc_2: 0.8556\n",
            "Epoch 00146: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 147/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4606 - accuracy: 0.7743 - auc_2: 0.8601\n",
            "Epoch 00147: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 148/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4731 - accuracy: 0.7648 - auc_2: 0.8515\n",
            "Epoch 00148: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 149/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4637 - accuracy: 0.7714 - auc_2: 0.8581\n",
            "Epoch 00149: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 150/500\n",
            "41/52 [======================>.......] - ETA: 0s - loss: 0.4674 - accuracy: 0.7768 - auc_2: 0.8559\n",
            "Epoch 00150: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 151/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4500 - accuracy: 0.7853 - auc_2: 0.8715\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 152/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4601 - accuracy: 0.7767 - auc_2: 0.8591\n",
            "Epoch 00152: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 153/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4631 - accuracy: 0.7816 - auc_2: 0.8581\n",
            "Epoch 00153: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 154/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4559 - accuracy: 0.7750 - auc_2: 0.8642\n",
            "Epoch 00154: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 155/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4688 - accuracy: 0.7819 - auc_2: 0.8577\n",
            "Epoch 00155: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 156/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4697 - accuracy: 0.7750 - auc_2: 0.8535\n",
            "Epoch 00156: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 157/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4491 - accuracy: 0.7867 - auc_2: 0.8702\n",
            "Epoch 00157: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 158/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4646 - accuracy: 0.7792 - auc_2: 0.8599\n",
            "Epoch 00158: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 159/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4522 - accuracy: 0.7794 - auc_2: 0.8675\n",
            "Epoch 00159: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 160/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4617 - accuracy: 0.7762 - auc_2: 0.8598\n",
            "Epoch 00160: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 161/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4579 - accuracy: 0.7897 - auc_2: 0.8640\n",
            "Epoch 00161: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 162/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4724 - accuracy: 0.7719 - auc_2: 0.8514\n",
            "Epoch 00162: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 163/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4578 - accuracy: 0.7758 - auc_2: 0.8625\n",
            "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 164/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4609 - accuracy: 0.7697 - auc_2: 0.8598\n",
            "Epoch 00164: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 165/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4612 - accuracy: 0.7757 - auc_2: 0.8619\n",
            "Epoch 00165: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 166/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4588 - accuracy: 0.7828 - auc_2: 0.8591\n",
            "Epoch 00166: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 167/500\n",
            "22/52 [===========>..................] - ETA: 0s - loss: 0.4820 - accuracy: 0.7568 - auc_2: 0.8493\n",
            "Epoch 00167: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 168/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4500 - accuracy: 0.7861 - auc_2: 0.8690\n",
            "Epoch 00168: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 169/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4689 - accuracy: 0.7742 - auc_2: 0.8541\n",
            "Epoch 00169: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 170/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4519 - accuracy: 0.7855 - auc_2: 0.8674\n",
            "Epoch 00170: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 171/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4569 - accuracy: 0.7744 - auc_2: 0.8633\n",
            "Epoch 00171: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 172/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4721 - accuracy: 0.7662 - auc_2: 0.8493\n",
            "Epoch 00172: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 173/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4499 - accuracy: 0.7934 - auc_2: 0.8698\n",
            "Epoch 00173: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 174/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4669 - accuracy: 0.7676 - auc_2: 0.8552\n",
            "Epoch 00174: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 175/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4516 - accuracy: 0.7862 - auc_2: 0.8680\n",
            "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 176/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4631 - accuracy: 0.7721 - auc_2: 0.8563\n",
            "Epoch 00176: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 177/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4683 - accuracy: 0.7766 - auc_2: 0.8561\n",
            "Epoch 00177: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 178/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4743 - accuracy: 0.7628 - auc_2: 0.8507\n",
            "Epoch 00178: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 179/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4628 - accuracy: 0.7838 - auc_2: 0.8603\n",
            "Epoch 00179: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 180/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4679 - accuracy: 0.7647 - auc_2: 0.8543\n",
            "Epoch 00180: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 181/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4716 - accuracy: 0.7797 - auc_2: 0.8504\n",
            "Epoch 00181: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 182/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4581 - accuracy: 0.7679 - auc_2: 0.8633\n",
            "Epoch 00182: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 183/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4904 - accuracy: 0.7574 - auc_2: 0.8395\n",
            "Epoch 00183: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 184/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4504 - accuracy: 0.7809 - auc_2: 0.8669\n",
            "Epoch 00184: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 185/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4583 - accuracy: 0.7779 - auc_2: 0.8642\n",
            "Epoch 00185: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 186/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4588 - accuracy: 0.7825 - auc_2: 0.8616\n",
            "Epoch 00186: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 187/500\n",
            "42/52 [=======================>......] - ETA: 0s - loss: 0.4620 - accuracy: 0.7798 - auc_2: 0.8602\n",
            "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 188/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4614 - accuracy: 0.7767 - auc_2: 0.8592\n",
            "Epoch 00188: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 189/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4635 - accuracy: 0.7696 - auc_2: 0.8563\n",
            "Epoch 00189: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 190/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4623 - accuracy: 0.7816 - auc_2: 0.8611\n",
            "Epoch 00190: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 191/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4570 - accuracy: 0.7797 - auc_2: 0.8639\n",
            "Epoch 00191: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 192/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4497 - accuracy: 0.7882 - auc_2: 0.8693\n",
            "Epoch 00192: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 193/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4934 - accuracy: 0.7466 - auc_2: 0.8361\n",
            "Epoch 00193: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 194/500\n",
            "43/52 [=======================>......] - ETA: 0s - loss: 0.4692 - accuracy: 0.7733 - auc_2: 0.8525\n",
            "Epoch 00194: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 195/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4446 - accuracy: 0.7900 - auc_2: 0.8729\n",
            "Epoch 00195: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 196/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4694 - accuracy: 0.7708 - auc_2: 0.8532\n",
            "Epoch 00196: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 197/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4752 - accuracy: 0.7676 - auc_2: 0.8515\n",
            "Epoch 00197: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 198/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4658 - accuracy: 0.7758 - auc_2: 0.8597\n",
            "Epoch 00198: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 199/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4829 - accuracy: 0.7672 - auc_2: 0.8418\n",
            "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 200/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4591 - accuracy: 0.7795 - auc_2: 0.8619\n",
            "Epoch 00200: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 201/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4376 - accuracy: 0.7953 - auc_2: 0.8765\n",
            "Epoch 00201: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 202/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4521 - accuracy: 0.7862 - auc_2: 0.8686\n",
            "Epoch 00202: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 203/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4834 - accuracy: 0.7527 - auc_2: 0.8424\n",
            "Epoch 00203: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 204/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4762 - accuracy: 0.7733 - auc_2: 0.8506\n",
            "Epoch 00204: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 205/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4770 - accuracy: 0.7625 - auc_2: 0.8456\n",
            "Epoch 00205: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 206/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4673 - accuracy: 0.7722 - auc_2: 0.8556\n",
            "Epoch 00206: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 207/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4465 - accuracy: 0.7942 - auc_2: 0.8728\n",
            "Epoch 00207: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 208/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4657 - accuracy: 0.7758 - auc_2: 0.8568\n",
            "Epoch 00208: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 209/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4512 - accuracy: 0.7842 - auc_2: 0.8697\n",
            "Epoch 00209: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 210/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4627 - accuracy: 0.7643 - auc_2: 0.8592\n",
            "Epoch 00210: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 211/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4722 - accuracy: 0.7833 - auc_2: 0.8553\n",
            "Epoch 00211: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 212/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4278 - accuracy: 0.8016 - auc_2: 0.8873\n",
            "Epoch 00212: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 213/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4418 - accuracy: 0.7923 - auc_2: 0.8750\n",
            "Epoch 00213: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 214/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4661 - accuracy: 0.7671 - auc_2: 0.8551\n",
            "Epoch 00214: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 215/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4794 - accuracy: 0.7515 - auc_2: 0.8432\n",
            "Epoch 00215: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 216/500\n",
            "40/52 [======================>.......] - ETA: 0s - loss: 0.4612 - accuracy: 0.7763 - auc_2: 0.8601\n",
            "Epoch 00216: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 217/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4693 - accuracy: 0.7789 - auc_2: 0.8552\n",
            "Epoch 00217: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 218/500\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.4594 - accuracy: 0.7781 - auc_2: 0.8624\n",
            "Epoch 00218: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 219/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4528 - accuracy: 0.7806 - auc_2: 0.8667\n",
            "Epoch 00219: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 220/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4603 - accuracy: 0.7757 - auc_2: 0.8597\n",
            "Epoch 00220: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 221/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4630 - accuracy: 0.7694 - auc_2: 0.8568\n",
            "Epoch 00221: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 222/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4616 - accuracy: 0.7758 - auc_2: 0.8599\n",
            "Epoch 00222: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 223/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4704 - accuracy: 0.7708 - auc_2: 0.8521\n",
            "Epoch 00223: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 224/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4719 - accuracy: 0.7625 - auc_2: 0.8550\n",
            "Epoch 00224: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 225/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4651 - accuracy: 0.7727 - auc_2: 0.8581\n",
            "Epoch 00225: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 226/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4589 - accuracy: 0.7774 - auc_2: 0.8620\n",
            "Epoch 00226: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577\n",
            "Epoch 00227: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 228/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4603 - accuracy: 0.7712 - auc_2: 0.8587\n",
            "Epoch 00228: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 229/500\n",
            "23/52 [============>.................] - ETA: 0s - loss: 0.4572 - accuracy: 0.7804 - auc_2: 0.8647\n",
            "Epoch 00229: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 230/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4553 - accuracy: 0.7857 - auc_2: 0.8668\n",
            "Epoch 00230: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 231/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4569 - accuracy: 0.7870 - auc_2: 0.8637\n",
            "Epoch 00231: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 232/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4687 - accuracy: 0.7750 - auc_2: 0.8570\n",
            "Epoch 00232: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 233/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4550 - accuracy: 0.7900 - auc_2: 0.8656\n",
            "Epoch 00233: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 234/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4572 - accuracy: 0.7883 - auc_2: 0.8626\n",
            "Epoch 00234: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 235/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4664 - accuracy: 0.7708 - auc_2: 0.8575\n",
            "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 236/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4686 - accuracy: 0.7770 - auc_2: 0.8571\n",
            "Epoch 00236: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 237/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4718 - accuracy: 0.7671 - auc_2: 0.8517\n",
            "Epoch 00237: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 238/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4782 - accuracy: 0.7711 - auc_2: 0.8470\n",
            "Epoch 00238: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 239/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4721 - accuracy: 0.7750 - auc_2: 0.8519\n",
            "Epoch 00239: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 240/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4514 - accuracy: 0.7859 - auc_2: 0.8684\n",
            "Epoch 00240: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 241/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4751 - accuracy: 0.7608 - auc_2: 0.8486\n",
            "Epoch 00241: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 242/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4714 - accuracy: 0.7617 - auc_2: 0.8532\n",
            "Epoch 00242: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 243/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4412 - accuracy: 0.8200 - auc_2: 0.8790\n",
            "Epoch 00243: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 244/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4781 - accuracy: 0.7636 - auc_2: 0.8460\n",
            "Epoch 00244: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 245/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4493 - accuracy: 0.7833 - auc_2: 0.8691\n",
            "Epoch 00245: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 246/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4554 - accuracy: 0.7733 - auc_2: 0.8646\n",
            "Epoch 00246: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 247/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4544 - accuracy: 0.7806 - auc_2: 0.8630\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 248/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4653 - accuracy: 0.7694 - auc_2: 0.8577\n",
            "Epoch 00248: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 249/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4538 - accuracy: 0.7774 - auc_2: 0.8645\n",
            "Epoch 00249: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 250/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4642 - accuracy: 0.7814 - auc_2: 0.8602\n",
            "Epoch 00250: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 251/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4782 - accuracy: 0.7600 - auc_2: 0.8484\n",
            "Epoch 00251: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 252/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4767 - accuracy: 0.7625 - auc_2: 0.8468\n",
            "Epoch 00252: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 253/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4515 - accuracy: 0.7781 - auc_2: 0.8643\n",
            "Epoch 00253: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 254/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4650 - accuracy: 0.7788 - auc_2: 0.8574\n",
            "Epoch 00254: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 255/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4681 - accuracy: 0.7661 - auc_2: 0.8569\n",
            "Epoch 00255: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 256/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4727 - accuracy: 0.7758 - auc_2: 0.8526\n",
            "Epoch 00256: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 257/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4857 - accuracy: 0.7514 - auc_2: 0.8416\n",
            "Epoch 00257: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 258/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4576 - accuracy: 0.7850 - auc_2: 0.8639\n",
            "Epoch 00258: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 259/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4664 - accuracy: 0.7682 - auc_2: 0.8536\n",
            "Epoch 00259: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 260/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4744 - accuracy: 0.7650 - auc_2: 0.8464\n",
            "Epoch 00260: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 261/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4593 - accuracy: 0.7765 - auc_2: 0.8613\n",
            "Epoch 00261: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 262/500\n",
            "38/52 [====================>.........] - ETA: 0s - loss: 0.4743 - accuracy: 0.7645 - auc_2: 0.8508\n",
            "Epoch 00262: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 263/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4641 - accuracy: 0.7714 - auc_2: 0.8565\n",
            "Epoch 00263: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 264/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4698 - accuracy: 0.7703 - auc_2: 0.8560\n",
            "Epoch 00264: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 265/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4750 - accuracy: 0.7622 - auc_2: 0.8478\n",
            "Epoch 00265: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 266/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4853 - accuracy: 0.7586 - auc_2: 0.8404\n",
            "Epoch 00266: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 267/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4579 - accuracy: 0.7879 - auc_2: 0.8622\n",
            "Epoch 00267: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 268/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4509 - accuracy: 0.7804 - auc_2: 0.8658\n",
            "Epoch 00268: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 269/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4772 - accuracy: 0.7688 - auc_2: 0.8474\n",
            "Epoch 00269: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 270/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7750 - auc_2: 0.8575\n",
            "Epoch 00270: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 271/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4641 - accuracy: 0.7800 - auc_2: 0.8581\n",
            "Epoch 00271: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 272/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4699 - accuracy: 0.7609 - auc_2: 0.8547\n",
            "Epoch 00272: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 273/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4621 - accuracy: 0.7806 - auc_2: 0.8608\n",
            "Epoch 00273: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 274/500\n",
            "39/52 [=====================>........] - ETA: 0s - loss: 0.4630 - accuracy: 0.7769 - auc_2: 0.8598\n",
            "Epoch 00274: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 275/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4525 - accuracy: 0.7857 - auc_2: 0.8676\n",
            "Epoch 00275: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 276/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4608 - accuracy: 0.7847 - auc_2: 0.8609\n",
            "Epoch 00276: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 277/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4343 - accuracy: 0.7860 - auc_2: 0.8808\n",
            "Epoch 00277: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 278/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4509 - accuracy: 0.7875 - auc_2: 0.8668\n",
            "Epoch 00278: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 279/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4813 - accuracy: 0.7679 - auc_2: 0.8483\n",
            "Epoch 00279: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 280/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4746 - accuracy: 0.7650 - auc_2: 0.8497\n",
            "Epoch 00280: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 281/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4739 - accuracy: 0.7750 - auc_2: 0.8507\n",
            "Epoch 00281: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 282/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4617 - accuracy: 0.7667 - auc_2: 0.8604\n",
            "Epoch 00282: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 283/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4607 - accuracy: 0.7804 - auc_2: 0.8588\n",
            "Epoch 00283: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577\n",
            "Epoch 00284: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 285/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7722 - auc_2: 0.8534\n",
            "Epoch 00285: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 286/500\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.4660 - accuracy: 0.7689 - auc_2: 0.8571\n",
            "Epoch 00286: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 287/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4716 - accuracy: 0.7691 - auc_2: 0.8520\n",
            "Epoch 00287: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 288/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4787 - accuracy: 0.7589 - auc_2: 0.8475\n",
            "Epoch 00288: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 289/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4746 - accuracy: 0.7656 - auc_2: 0.8495\n",
            "Epoch 00289: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 290/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4591 - accuracy: 0.7696 - auc_2: 0.8619\n",
            "Epoch 00290: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 291/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4694 - accuracy: 0.7735 - auc_2: 0.8540\n",
            "Epoch 00291: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 292/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4775 - accuracy: 0.7691 - auc_2: 0.8510\n",
            "Epoch 00292: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 293/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4369 - accuracy: 0.7942 - auc_2: 0.8775\n",
            "Epoch 00293: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 294/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4577 - accuracy: 0.7786 - auc_2: 0.8602\n",
            "Epoch 00294: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 295/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4865 - accuracy: 0.7683 - auc_2: 0.8433\n",
            "Epoch 00295: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 296/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4679 - accuracy: 0.7722 - auc_2: 0.8532\n",
            "Epoch 00296: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 297/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4736 - accuracy: 0.7708 - auc_2: 0.8494\n",
            "Epoch 00297: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 298/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4915 - accuracy: 0.7636 - auc_2: 0.8368\n",
            "Epoch 00298: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 299/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4468 - accuracy: 0.7800 - auc_2: 0.8700\n",
            "Epoch 00299: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 300/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4673 - accuracy: 0.7750 - auc_2: 0.8539\n",
            "Epoch 00300: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 301/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4597 - accuracy: 0.7769 - auc_2: 0.8615\n",
            "Epoch 00301: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 302/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4706 - accuracy: 0.7621 - auc_2: 0.8504\n",
            "Epoch 00302: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 303/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4475 - accuracy: 0.7966 - auc_2: 0.8731\n",
            "Epoch 00303: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 304/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4699 - accuracy: 0.7688 - auc_2: 0.8549\n",
            "Epoch 00304: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 305/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4536 - accuracy: 0.7909 - auc_2: 0.8669\n",
            "Epoch 00305: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 306/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4611 - accuracy: 0.7743 - auc_2: 0.8598\n",
            "Epoch 00306: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 307/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4564 - accuracy: 0.7750 - auc_2: 0.8641\n",
            "Epoch 00307: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
            "\n",
            "Epoch 00307: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 308/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4514 - accuracy: 0.7903 - auc_2: 0.8671\n",
            "Epoch 00308: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 309/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4457 - accuracy: 0.7914 - auc_2: 0.8736\n",
            "Epoch 00309: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 310/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4661 - accuracy: 0.7796 - auc_2: 0.8587\n",
            "Epoch 00310: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 311/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4737 - accuracy: 0.7613 - auc_2: 0.8482\n",
            "Epoch 00311: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 312/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4675 - accuracy: 0.7726 - auc_2: 0.8546\n",
            "Epoch 00312: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 313/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4578 - accuracy: 0.7790 - auc_2: 0.8634\n",
            "Epoch 00313: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 314/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4768 - accuracy: 0.7567 - auc_2: 0.8490\n",
            "Epoch 00314: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 315/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4534 - accuracy: 0.7907 - auc_2: 0.8691\n",
            "Epoch 00315: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 316/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4620 - accuracy: 0.7726 - auc_2: 0.8593\n",
            "Epoch 00316: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 317/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4549 - accuracy: 0.7809 - auc_2: 0.8663\n",
            "Epoch 00317: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 318/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4598 - accuracy: 0.7800 - auc_2: 0.8649\n",
            "Epoch 00318: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 319/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4778 - accuracy: 0.7683 - auc_2: 0.8498\n",
            "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 320/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4702 - accuracy: 0.7716 - auc_2: 0.8531\n",
            "Epoch 00320: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 321/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4556 - accuracy: 0.7839 - auc_2: 0.8660\n",
            "Epoch 00321: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 322/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4620 - accuracy: 0.7742 - auc_2: 0.8580\n",
            "Epoch 00322: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 323/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4805 - accuracy: 0.7597 - auc_2: 0.8431\n",
            "Epoch 00323: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 324/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4556 - accuracy: 0.7781 - auc_2: 0.8637\n",
            "Epoch 00324: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 325/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4570 - accuracy: 0.7677 - auc_2: 0.8619\n",
            "Epoch 00325: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 326/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4702 - accuracy: 0.7733 - auc_2: 0.8542\n",
            "Epoch 00326: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 327/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4676 - accuracy: 0.7688 - auc_2: 0.8538\n",
            "Epoch 00327: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 328/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4618 - accuracy: 0.7741 - auc_2: 0.8609\n",
            "Epoch 00328: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 329/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4914 - accuracy: 0.7435 - auc_2: 0.8372\n",
            "Epoch 00329: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 330/500\n",
            "24/52 [============>.................] - ETA: 0s - loss: 0.4747 - accuracy: 0.7667 - auc_2: 0.8531\n",
            "Epoch 00330: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 331/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4615 - accuracy: 0.7914 - auc_2: 0.8611\n",
            "Epoch 00331: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 332/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4687 - accuracy: 0.7714 - auc_2: 0.8532\n",
            "Epoch 00332: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 333/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4603 - accuracy: 0.7800 - auc_2: 0.8612\n",
            "Epoch 00333: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 334/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4556 - accuracy: 0.7855 - auc_2: 0.8611\n",
            "Epoch 00334: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 335/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4609 - accuracy: 0.7735 - auc_2: 0.8588\n",
            "Epoch 00335: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 336/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4640 - accuracy: 0.7712 - auc_2: 0.8587\n",
            "Epoch 00336: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 337/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4659 - accuracy: 0.7729 - auc_2: 0.8578\n",
            "Epoch 00337: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 338/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4487 - accuracy: 0.7889 - auc_2: 0.8753\n",
            "Epoch 00338: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 339/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4444 - accuracy: 0.7914 - auc_2: 0.8745\n",
            "Epoch 00339: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 340/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4771 - accuracy: 0.7758 - auc_2: 0.8492\n",
            "Epoch 00340: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 341/500\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.7765 - auc_2: 0.8591\n",
            "Epoch 00341: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 342/500\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.4683 - accuracy: 0.7729 - auc_2: 0.8540\n",
            "Epoch 00342: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 343/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4539 - accuracy: 0.7768 - auc_2: 0.8656\n",
            "Epoch 00343: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 344/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4366 - accuracy: 0.7981 - auc_2: 0.8773\n",
            "Epoch 00344: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 345/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4932 - accuracy: 0.7323 - auc_2: 0.8316\n",
            "Epoch 00345: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 346/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4477 - accuracy: 0.7850 - auc_2: 0.8704\n",
            "Epoch 00346: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 347/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4952 - accuracy: 0.7530 - auc_2: 0.8329\n",
            "Epoch 00347: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 348/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4690 - accuracy: 0.7707 - auc_2: 0.8551\n",
            "Epoch 00348: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 349/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4619 - accuracy: 0.7833 - auc_2: 0.8641\n",
            "Epoch 00349: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 350/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4451 - accuracy: 0.7914 - auc_2: 0.8730\n",
            "Epoch 00350: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 351/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4824 - accuracy: 0.7614 - auc_2: 0.8432\n",
            "Epoch 00351: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 352/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4837 - accuracy: 0.7580 - auc_2: 0.8422\n",
            "Epoch 00352: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 353/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4662 - accuracy: 0.7774 - auc_2: 0.8552\n",
            "Epoch 00353: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 354/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4622 - accuracy: 0.7800 - auc_2: 0.8596\n",
            "Epoch 00354: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 355/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4567 - accuracy: 0.7929 - auc_2: 0.8622\n",
            "Epoch 00355: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 356/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4677 - accuracy: 0.7742 - auc_2: 0.8571\n",
            "Epoch 00356: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 357/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4415 - accuracy: 0.8000 - auc_2: 0.8757\n",
            "Epoch 00357: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 358/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4650 - accuracy: 0.7812 - auc_2: 0.8567\n",
            "Epoch 00358: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 359/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4527 - accuracy: 0.7806 - auc_2: 0.8677\n",
            "Epoch 00359: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 360/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4672 - accuracy: 0.7759 - auc_2: 0.8549\n",
            "Epoch 00360: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 361/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4609 - accuracy: 0.7760 - auc_2: 0.8576\n",
            "Epoch 00361: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 362/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4659 - accuracy: 0.7774 - auc_2: 0.8594\n",
            "Epoch 00362: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 363/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4518 - accuracy: 0.7793 - auc_2: 0.8669\n",
            "Epoch 00363: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 364/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4655 - accuracy: 0.7771 - auc_2: 0.8586\n",
            "Epoch 00364: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 365/500\n",
            "37/52 [====================>.........] - ETA: 0s - loss: 0.4553 - accuracy: 0.7851 - auc_2: 0.8644\n",
            "Epoch 00365: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 366/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4736 - accuracy: 0.7603 - auc_2: 0.8515\n",
            "Epoch 00366: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 367/500\n",
            "24/52 [============>.................] - ETA: 0s - loss: 0.4648 - accuracy: 0.7750 - auc_2: 0.8566\n",
            "Epoch 00367: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 368/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4894 - accuracy: 0.7621 - auc_2: 0.8395\n",
            "Epoch 00368: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 369/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4462 - accuracy: 0.7778 - auc_2: 0.8728\n",
            "Epoch 00369: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 370/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4737 - accuracy: 0.7667 - auc_2: 0.8509\n",
            "Epoch 00370: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 371/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4716 - accuracy: 0.7625 - auc_2: 0.8489\n",
            "Epoch 00371: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 372/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4961 - accuracy: 0.7481 - auc_2: 0.8328\n",
            "Epoch 00372: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 373/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4610 - accuracy: 0.7889 - auc_2: 0.8592\n",
            "Epoch 00373: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 374/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4632 - accuracy: 0.7661 - auc_2: 0.8579\n",
            "Epoch 00374: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 375/500\n",
            "21/52 [===========>..................] - ETA: 0s - loss: 0.4705 - accuracy: 0.7762 - auc_2: 0.8525\n",
            "Epoch 00375: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 376/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4746 - accuracy: 0.7625 - auc_2: 0.8503\n",
            "Epoch 00376: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 377/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4581 - accuracy: 0.7707 - auc_2: 0.8616\n",
            "Epoch 00377: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 378/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4751 - accuracy: 0.7621 - auc_2: 0.8496\n",
            "Epoch 00378: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 379/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4732 - accuracy: 0.7707 - auc_2: 0.8490\n",
            "Epoch 00379: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
            "\n",
            "Epoch 00379: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 380/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4509 - accuracy: 0.7781 - auc_2: 0.8684\n",
            "Epoch 00380: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 381/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4621 - accuracy: 0.7833 - auc_2: 0.8597\n",
            "Epoch 00381: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 382/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4442 - accuracy: 0.7845 - auc_2: 0.8747\n",
            "Epoch 00382: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 383/500\n",
            "36/52 [===================>..........] - ETA: 0s - loss: 0.4499 - accuracy: 0.7792 - auc_2: 0.8692\n",
            "Epoch 00383: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 384/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4507 - accuracy: 0.7707 - auc_2: 0.8669\n",
            "Epoch 00384: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 385/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4561 - accuracy: 0.7710 - auc_2: 0.8633\n",
            "Epoch 00385: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 386/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4631 - accuracy: 0.7810 - auc_2: 0.8594\n",
            "Epoch 00386: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 387/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4478 - accuracy: 0.7919 - auc_2: 0.8704\n",
            "Epoch 00387: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 388/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4428 - accuracy: 0.7929 - auc_2: 0.8740\n",
            "Epoch 00388: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 389/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4640 - accuracy: 0.7855 - auc_2: 0.8610\n",
            "Epoch 00389: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 390/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4887 - accuracy: 0.7531 - auc_2: 0.8389\n",
            "Epoch 00390: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 391/500\n",
            "21/52 [===========>..................] - ETA: 0s - loss: 0.4750 - accuracy: 0.7714 - auc_2: 0.8510\n",
            "Epoch 00391: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 392/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4787 - accuracy: 0.7613 - auc_2: 0.8464\n",
            "Epoch 00392: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 393/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7638 - auc_2: 0.8567\n",
            "Epoch 00393: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 394/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4564 - accuracy: 0.7894 - auc_2: 0.8659\n",
            "Epoch 00394: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 395/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4638 - accuracy: 0.7759 - auc_2: 0.8579\n",
            "Epoch 00395: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 396/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4680 - accuracy: 0.7683 - auc_2: 0.8554\n",
            "Epoch 00396: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 397/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4758 - accuracy: 0.7574 - auc_2: 0.8494\n",
            "Epoch 00397: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 398/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4762 - accuracy: 0.7714 - auc_2: 0.8464\n",
            "Epoch 00398: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 399/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4635 - accuracy: 0.7768 - auc_2: 0.8627\n",
            "Epoch 00399: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 400/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4332 - accuracy: 0.7914 - auc_2: 0.8829\n",
            "Epoch 00400: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 401/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4474 - accuracy: 0.7800 - auc_2: 0.8714\n",
            "Epoch 00401: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 402/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4764 - accuracy: 0.7536 - auc_2: 0.8498\n",
            "Epoch 00402: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 403/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4646 - accuracy: 0.7850 - auc_2: 0.8577\n",
            "Epoch 00403: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 404/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4448 - accuracy: 0.8000 - auc_2: 0.8712\n",
            "Epoch 00404: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 405/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4633 - accuracy: 0.7769 - auc_2: 0.8582\n",
            "Epoch 00405: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 406/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4487 - accuracy: 0.7852 - auc_2: 0.8720\n",
            "Epoch 00406: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 407/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4686 - accuracy: 0.7707 - auc_2: 0.8547\n",
            "Epoch 00407: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 408/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4596 - accuracy: 0.7909 - auc_2: 0.8637\n",
            "Epoch 00408: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 409/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4531 - accuracy: 0.7732 - auc_2: 0.8656\n",
            "Epoch 00409: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 410/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4799 - accuracy: 0.7769 - auc_2: 0.8449\n",
            "Epoch 00410: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 411/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4527 - accuracy: 0.7778 - auc_2: 0.8676\n",
            "Epoch 00411: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 412/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4368 - accuracy: 0.8052 - auc_2: 0.8807\n",
            "Epoch 00412: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 413/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4639 - accuracy: 0.7776 - auc_2: 0.8566\n",
            "Epoch 00413: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 414/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4568 - accuracy: 0.7879 - auc_2: 0.8635\n",
            "Epoch 00414: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 415/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4709 - accuracy: 0.7750 - auc_2: 0.8518\n",
            "Epoch 00415: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 416/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4571 - accuracy: 0.7839 - auc_2: 0.8643\n",
            "Epoch 00416: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 417/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4810 - accuracy: 0.7563 - auc_2: 0.8440\n",
            "Epoch 00417: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 418/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4784 - accuracy: 0.7625 - auc_2: 0.8497\n",
            "Epoch 00418: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 419/500\n",
            "23/52 [============>.................] - ETA: 0s - loss: 0.4591 - accuracy: 0.7783 - auc_2: 0.8595\n",
            "Epoch 00419: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 420/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4634 - accuracy: 0.7700 - auc_2: 0.8578\n",
            "Epoch 00420: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 421/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4803 - accuracy: 0.7552 - auc_2: 0.8408\n",
            "Epoch 00421: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 422/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4691 - accuracy: 0.7850 - auc_2: 0.8541\n",
            "Epoch 00422: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 423/500\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.4634 - accuracy: 0.7770 - auc_2: 0.8585\n",
            "Epoch 00423: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 424/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4693 - accuracy: 0.7655 - auc_2: 0.8550\n",
            "Epoch 00424: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 425/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4474 - accuracy: 0.7889 - auc_2: 0.8715\n",
            "Epoch 00425: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 426/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4574 - accuracy: 0.7838 - auc_2: 0.8669\n",
            "Epoch 00426: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 427/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4588 - accuracy: 0.7870 - auc_2: 0.8646\n",
            "Epoch 00427: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 428/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4817 - accuracy: 0.7558 - auc_2: 0.8449\n",
            "Epoch 00428: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 429/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4607 - accuracy: 0.7828 - auc_2: 0.8590\n",
            "Epoch 00429: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 430/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4576 - accuracy: 0.7806 - auc_2: 0.8644\n",
            "Epoch 00430: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 431/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.5084 - accuracy: 0.7400 - auc_2: 0.8220\n",
            "Epoch 00431: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 432/500\n",
            "23/52 [============>.................] - ETA: 0s - loss: 0.4741 - accuracy: 0.7761 - auc_2: 0.8516\n",
            "Epoch 00432: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 433/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4629 - accuracy: 0.7750 - auc_2: 0.8610\n",
            "Epoch 00433: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 434/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4729 - accuracy: 0.7740 - auc_2: 0.8508\n",
            "Epoch 00434: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 435/500\n",
            "23/52 [============>.................] - ETA: 0s - loss: 0.4645 - accuracy: 0.7717 - auc_2: 0.8579\n",
            "Epoch 00435: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 436/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4479 - accuracy: 0.7920 - auc_2: 0.8721\n",
            "Epoch 00436: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 437/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4585 - accuracy: 0.7780 - auc_2: 0.8605\n",
            "Epoch 00437: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 438/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4659 - accuracy: 0.7742 - auc_2: 0.8560\n",
            "Epoch 00438: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 439/500\n",
            "22/52 [===========>..................] - ETA: 0s - loss: 0.4707 - accuracy: 0.7659 - auc_2: 0.8526\n",
            "Epoch 00439: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 440/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4327 - accuracy: 0.7955 - auc_2: 0.8823\n",
            "Epoch 00440: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 441/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4701 - accuracy: 0.7780 - auc_2: 0.8536\n",
            "Epoch 00441: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 442/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4793 - accuracy: 0.7690 - auc_2: 0.8437\n",
            "Epoch 00442: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 443/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4741 - accuracy: 0.7690 - auc_2: 0.8493\n",
            "Epoch 00443: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 444/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4650 - accuracy: 0.7685 - auc_2: 0.8539\n",
            "Epoch 00444: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 445/500\n",
            "23/52 [============>.................] - ETA: 0s - loss: 0.4703 - accuracy: 0.7717 - auc_2: 0.8461\n",
            "Epoch 00445: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 446/500\n",
            "24/52 [============>.................] - ETA: 0s - loss: 0.4917 - accuracy: 0.7688 - auc_2: 0.8400\n",
            "Epoch 00446: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 447/500\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.4672 - accuracy: 0.7740 - auc_2: 0.8558\n",
            "Epoch 00447: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 448/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4827 - accuracy: 0.7621 - auc_2: 0.8450\n",
            "Epoch 00448: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 449/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4453 - accuracy: 0.7950 - auc_2: 0.8740\n",
            "Epoch 00449: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 450/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4567 - accuracy: 0.7817 - auc_2: 0.8641\n",
            "Epoch 00450: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 451/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4711 - accuracy: 0.7700 - auc_2: 0.8533\n",
            "Epoch 00451: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 452/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4566 - accuracy: 0.7758 - auc_2: 0.8640\n",
            "Epoch 00452: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 453/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4693 - accuracy: 0.7759 - auc_2: 0.8548\n",
            "Epoch 00453: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 454/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4768 - accuracy: 0.7679 - auc_2: 0.8486\n",
            "Epoch 00454: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 455/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4555 - accuracy: 0.7793 - auc_2: 0.8636\n",
            "Epoch 00455: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 456/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4685 - accuracy: 0.7625 - auc_2: 0.8520\n",
            "Epoch 00456: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 457/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4745 - accuracy: 0.7661 - auc_2: 0.8499\n",
            "Epoch 00457: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 458/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4306 - accuracy: 0.7983 - auc_2: 0.8833\n",
            "Epoch 00458: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 459/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4286 - accuracy: 0.8054 - auc_2: 0.8864\n",
            "Epoch 00459: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 460/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4705 - accuracy: 0.7750 - auc_2: 0.8540\n",
            "Epoch 00460: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 461/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4449 - accuracy: 0.7911 - auc_2: 0.8714\n",
            "Epoch 00461: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 462/500\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.4632 - accuracy: 0.7740 - auc_2: 0.8585\n",
            "Epoch 00462: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 463/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4815 - accuracy: 0.7638 - auc_2: 0.8475\n",
            "Epoch 00463: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 464/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4509 - accuracy: 0.7933 - auc_2: 0.8657\n",
            "Epoch 00464: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 465/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4679 - accuracy: 0.7629 - auc_2: 0.8554\n",
            "Epoch 00465: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 466/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4624 - accuracy: 0.7750 - auc_2: 0.8587\n",
            "Epoch 00466: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 467/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4777 - accuracy: 0.7620 - auc_2: 0.8444\n",
            "Epoch 00467: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 468/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4817 - accuracy: 0.7569 - auc_2: 0.8457\n",
            "Epoch 00468: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577\n",
            "Epoch 00469: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 470/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4558 - accuracy: 0.7788 - auc_2: 0.8633\n",
            "Epoch 00470: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 471/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4646 - accuracy: 0.7656 - auc_2: 0.8585\n",
            "Epoch 00471: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 472/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4461 - accuracy: 0.7985 - auc_2: 0.8756\n",
            "Epoch 00472: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 473/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4897 - accuracy: 0.7613 - auc_2: 0.8420\n",
            "Epoch 00473: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 474/500\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.7725 - auc_2: 0.8570\n",
            "Epoch 00474: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 475/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4503 - accuracy: 0.7923 - auc_2: 0.8683\n",
            "Epoch 00475: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 476/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4840 - accuracy: 0.7661 - auc_2: 0.8404\n",
            "Epoch 00476: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 477/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4833 - accuracy: 0.7569 - auc_2: 0.8437\n",
            "Epoch 00477: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 478/500\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.4623 - accuracy: 0.7800 - auc_2: 0.8596\n",
            "Epoch 00478: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 479/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4604 - accuracy: 0.7803 - auc_2: 0.8606\n",
            "Epoch 00479: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 480/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4553 - accuracy: 0.7883 - auc_2: 0.8651\n",
            "Epoch 00480: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 481/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4746 - accuracy: 0.7607 - auc_2: 0.8502\n",
            "Epoch 00481: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 482/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4595 - accuracy: 0.7829 - auc_2: 0.8634\n",
            "Epoch 00482: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 483/500\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4526 - accuracy: 0.7758 - auc_2: 0.8654\n",
            "Epoch 00483: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 484/500\n",
            "35/52 [===================>..........] - ETA: 0s - loss: 0.4618 - accuracy: 0.7686 - auc_2: 0.8580\n",
            "Epoch 00484: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 485/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4444 - accuracy: 0.7920 - auc_2: 0.8757\n",
            "Epoch 00485: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 486/500\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.4641 - accuracy: 0.7771 - auc_2: 0.8584\n",
            "Epoch 00486: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 487/500\n",
            "29/52 [===============>..............] - ETA: 0s - loss: 0.4550 - accuracy: 0.7828 - auc_2: 0.8689\n",
            "Epoch 00487: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 488/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4568 - accuracy: 0.7860 - auc_2: 0.8644\n",
            "Epoch 00488: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 489/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4606 - accuracy: 0.7625 - auc_2: 0.8609\n",
            "Epoch 00489: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 490/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4654 - accuracy: 0.7696 - auc_2: 0.8566\n",
            "Epoch 00490: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 491/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4707 - accuracy: 0.7696 - auc_2: 0.8521\n",
            "Epoch 00491: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 492/500\n",
            "27/52 [==============>...............] - ETA: 0s - loss: 0.4628 - accuracy: 0.7889 - auc_2: 0.8621\n",
            "Epoch 00492: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 493/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4655 - accuracy: 0.7720 - auc_2: 0.8576\n",
            "Epoch 00493: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 494/500\n",
            "34/52 [==================>...........] - ETA: 0s - loss: 0.4577 - accuracy: 0.7912 - auc_2: 0.8617\n",
            "Epoch 00494: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 495/500\n",
            "30/52 [================>.............] - ETA: 0s - loss: 0.4729 - accuracy: 0.7667 - auc_2: 0.8531\n",
            "Epoch 00495: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 496/500\n",
            "25/52 [=============>................] - ETA: 0s - loss: 0.4384 - accuracy: 0.7960 - auc_2: 0.8754\n",
            "Epoch 00496: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 497/500\n",
            "32/52 [=================>............] - ETA: 0s - loss: 0.4969 - accuracy: 0.7563 - auc_2: 0.8315\n",
            "Epoch 00497: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 498/500\n",
            "26/52 [==============>...............] - ETA: 0s - loss: 0.4785 - accuracy: 0.7558 - auc_2: 0.8459\n",
            "Epoch 00498: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 499/500\n",
            "28/52 [===============>..............] - ETA: 0s - loss: 0.4913 - accuracy: 0.7625 - auc_2: 0.8403\n",
            "Epoch 00499: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n",
            "Epoch 500/500\n",
            "31/52 [================>.............] - ETA: 0s - loss: 0.4810 - accuracy: 0.7677 - auc_2: 0.8438\n",
            "Epoch 00500: val_loss did not improve from 2.81551\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7742 - auc_2: 0.8577 - val_loss: 3.2635 - val_accuracy: 0.7093 - val_auc_2: 0.7525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnK-zHn8e2y3"
      },
      "source": [
        "# Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MQsRSWWe50V",
        "outputId": "4b75e60e-28fa-42c7-bc96-c9dab5f5f57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "preds = model.predict(x_test)\n",
        "confusion_matrix = tf.math.confusion_matrix(labels=y_test,predictions=(preds >= 0.5)).numpy() # Change decision threshold here\n",
        "print('Confusion matrix:\\n', confusion_matrix)\n",
        "print('Sensitivity: ', confusion_matrix[1][1] / (confusion_matrix[1][1] + confusion_matrix[1][0]))\n",
        "print('Specificity: ', confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[0][1]))\n",
        "print('PPV' + ': ', confusion_matrix[1][1] / (confusion_matrix[1][1] + confusion_matrix[0][1]))\n",
        "print('NPV' + ': ', confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[1][0]))\n",
        "sns.heatmap(confusion_matrix, annot=True)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            " [[98 19]\n",
            " [56 85]]\n",
            "Sensitivity:  0.6028368794326241\n",
            "Specificity:  0.8376068376068376\n",
            "PPV:  0.8173076923076923\n",
            "NPV:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d46df5be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4SPZOJMfiOW",
        "outputId": "6223906a-8b08-47e2-c648-4a4584e4e1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#AU-ROC\n",
        "from sklearn.metrics import roc_curve,accuracy_score\n",
        "from sklearn.metrics import auc\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "y_pred = model.predict(tf.convert_to_tensor(x_test))\n",
        "\n",
        "fpr_d, tpr_d, thresholds = roc_curve(y_test, y_pred)\n",
        "auc_d = auc(fpr_d, tpr_d)\n",
        "plt.plot(fpr_d, tpr_d, label='auc' + '(area = {:.3f})'.format(auc_d))\n",
        "\n",
        "    \n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKzI6sS0h4wF",
        "outputId": "4f19c802-0402-4eaf-92fd-b543bc3cca95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Accuracy Score\n",
        "accuracy_score(y_test, y_pred = (preds >= 0.5))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7093023255813954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voyh8A7Yx0Ly"
      },
      "source": [
        "# Extra Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmWB16EiwWkz"
      },
      "source": [
        "# from IPython import display\n",
        "# with pd.option_context('display.max_rows',50,'display.max_columns',90):\n",
        "#     display.display(input_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}